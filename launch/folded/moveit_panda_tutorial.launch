<!-- Do not launch in virtualenv -->

<launch>

  <!-- fake_mask_generator & fake_kinect2 should be open in virtualenv 'mask_rcnn'  -->



  <node name="to_panda_base" pkg="tf2_ros" type="static_transform_publisher" args="0 0 0 0 0 0 1 mdworld panda_link0" />

  <node name="to_camera_frame" pkg="tf2_ros" type="static_transform_publisher" args="0.1 -0.6 0.6 -1 0 -2.1 mdworld camera_frame" />

  <!-- <include file="$(find moveit_tutorials)/doc/perception_pipeline/launch/obstacle_avoidance_demo.launch" /> -->

  <include file="$(find panda_moveit_config)/launch/demo.launch" />

  <!-- fake Kinect2 node, publishing registered depth image and color image -->
    <!-- <node name="fake_kinect2_publisher" pkg="unknown_pick" type="fake_kinect2.py" /> -->

  <!-- segment cloud -->
  <node name="cloud_segmentor" pkg="unknown_pick" type="segment_cloud_v2" output="screen">
    <remap from="/cloud_obstacle" to="/camera/depth_registered/points"/>
    <!-- <remap from="/cloud_obstacle" to="/cloud_whatever" /> -->
    <param name="interested_object" value="orange" />
  </node>

  <!-- GPD package - generate suitable grasps -->
  <include file="$(find unknown_pick)/launch/grasp_detector.launch" />

  <!-- pose goal generator - convert GPD format into a pose -->
  <node name="pose_goal_generator" pkg="unknown_pick" type="pose_goal_generator.py" />

  <!-- Use MoveIt! command to config robot arm -->
  <node name="moveit_pregrasp_py" pkg="unknown_pick" type="moveit_pregrasp_py.py" output="screen"/>


</launch>
